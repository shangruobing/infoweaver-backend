{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8294a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filePath = r\"C:\\\\Users\\\\冰\\Desktop\\\\NFQA后端开发\\\\public\\\\Txt\"  # 文件夹路径\n",
    "# fileList:存放所有文件名（包含后缀）\n",
    "fileList = os.listdir(filePath)\n",
    "\n",
    "# 读取10个文件\n",
    "# fileList = fileList[:10]\n",
    "\n",
    "# textList:存放所有文件内容\n",
    "textList = []\n",
    "\n",
    "for file in fileList:\n",
    "    with open(os.path.join(filePath, file), encoding='UTF-8')as f:\n",
    "    # with open(os.path.join(filePath, file))as f:\n",
    "        # with open(os.path.join(filePath, file))as f:\n",
    "        # print(file)  # 文件名\n",
    "        # print(file)\n",
    "        textList.append(f.readlines())\n",
    "\n",
    "# result_text:对textList的内容进行处理\n",
    "result_text = []\n",
    "for i in textList:\n",
    "    result_text.append(''.join(i))\n",
    "\n",
    "# titleList:存放所有文件名（去除后缀）\n",
    "titleList = []\n",
    "for i in fileList:\n",
    "    titleList.append(i[:-4])\n",
    "\n",
    "# dataset: 存放最终数据 格式: 标题,内容\n",
    "dataset = []\n",
    "for i in range(len(titleList)):\n",
    "    dataset.append((titleList[i], result_text[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab67c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4353637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph, Node, Relationship\n",
    "\n",
    "graph = Graph(\"http://localhost:7474\", auth=(\"neo4j\", \"010209\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node(label, nodes):\n",
    "    \"\"\"\n",
    "    label:node type\n",
    "    nodes:node's name\n",
    "    \"\"\"\n",
    "    # for node_name in nodes:\n",
    "    node = Node(label, name=nodes)\n",
    "\n",
    "    # graph.create(node)\n",
    "    graph.merge(node, label, \"name\")\n",
    "    #print('create node success! total:', len(nodes))\n",
    "    #print('create node success!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76aa0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_relationship(start_node_label, end_node_label, start_node_name,\n",
    "                        end_node_name, rel_type, rel_name):\n",
    "    \"\"\"\n",
    "    example: 小明训练小华 小明和小华的类型是学生 训练的属性是1000米\n",
    "    start_node_label = '学生'\n",
    "    end_node_label = '学生'\n",
    "    start_node_name = '小明'\n",
    "    end_node_name = '小华'\n",
    "    rel_type = '训练'\n",
    "    rel_name = '1000米'\n",
    "    \"\"\"\n",
    "    #     query = \"match(p:%s),(q:%s) where p.name='%s'and q.name='%s' create (p)-[rel:%s{name:'%s'}]->(q)\" % (\n",
    "    query = \"match(p:%s),(q:%s) where p.name='%s'and q.name='%s' merge (p)-[rel:%s{name:'%s'}]->(q)\" % (\n",
    "        start_node_label, end_node_label, start_node_name, end_node_name,\n",
    "        rel_type, rel_name)\n",
    "    try:\n",
    "        graph.run(query)\n",
    "        # print('create relationship success! query:\\n', query)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc87e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# 加载lg模型\n",
    "nlp = spacy.load(\"zh_core_web_lg\")\n",
    "cfg = {\"segmenter\": \"jieba\"}\n",
    "nlp.from_config({\"nlp\": {\"tokenizer\": cfg}})\n",
    "# nlp.tokenizer.initialize(pkuseg_model=\"mixed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1cb76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(title, text):\n",
    "    \"\"\"单篇文章导入图数据库\"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # 存放spcay识别出来的ents\n",
    "    entity = set()\n",
    "    location = []\n",
    "    person = []\n",
    "    unit = []\n",
    "    for ent in doc.ents:\n",
    "        #     print(ent.text, ent.label_)\n",
    "        if ent.label_ in ['ORG', 'PERSON', 'WORK_OF_ART', 'LAW', 'LANGUAGE']:\n",
    "            entity.add((ent.text, ent.label_))\n",
    "\n",
    "        if ent.label_ == 'ORG':\n",
    "            unit.append((ent.text, 'org'))\n",
    "        if ent.label_ == 'LOC':\n",
    "            location.append((ent.text, 'location'))\n",
    "        if ent.label_ == 'GPE':  # 国家\n",
    "            location.append((ent.text, 'location'))\n",
    "        if ent.label_ == 'PERSON':\n",
    "            person.append((ent.text, 'person'))\n",
    "\n",
    "    relation = []\n",
    "    # objects:存放entity和nsubj（名词性主语）\n",
    "    objects = []\n",
    "    times = []\n",
    "    objects.extend(entity)\n",
    "\n",
    "    # 关系抽取\n",
    "    for token in doc:\n",
    "        # print('{0}({1}) <-- {2} -- {3}({4})'.format(token.text, token.tag_,\n",
    "        #                                             token.dep_, token.head.text,\n",
    "        #                                             token.head.tag_))\n",
    "\n",
    "        if token.dep_ == 'compound:nn' and token.tag_ == 'NT' and token.head.tag_ == 'NT':\n",
    "            times.append((token.text+token.head.text, 'time'))\n",
    "\n",
    "        if token.dep_ == 'nsubj':\n",
    "            #         print('{0}({1}) <-- {2} -- {3}({4})'.format(token.text, token.tag_,\n",
    "            #                                                     token.dep_,\n",
    "            #                                                     token.head.text,\n",
    "            #                                                     token.head.tag_))\n",
    "            objects.append((token.text, token.tag_))\n",
    "\n",
    "        if token.head.tag_ == 'VV':\n",
    "            if token.tag_ == 'NN':\n",
    "                if objects[-1][0] != token.text:\n",
    "                    #             print('{0}({1}) <-- {2} -- {3}({4})'.format(token.text, token.tag_,\n",
    "                    #                                                 token.dep_, token.head.text,\n",
    "                    #                                                 token.head.tag_))\n",
    "                    relation.append(\n",
    "                        (objects[-1][0], objects[-1][1], token.head.text,\n",
    "                         token.head.tag_, token.text, token.tag_))\n",
    "\n",
    "    # 创建Node Title 目前是一篇文章的root\n",
    "    create_node(label='Title', nodes=title)\n",
    "\n",
    "    # 创建Node Content 存放一篇文章的所有内容\n",
    "    content_name = 'Content'+title\n",
    "    create_node(label='Content', nodes=content_name)\n",
    "\n",
    "    # 创建Node File 存放一篇文章的原始文件\n",
    "    create_node(label='File', nodes=text)\n",
    "\n",
    "    # 创建Node Time 存放一篇文章的所有时间\n",
    "    time_name = 'Time'+title\n",
    "    create_node(label='Time', nodes=time_name)\n",
    "\n",
    "    # 创建Node Location 存放一篇文章的所有地理位置\n",
    "    loc_name = 'Loc'+title\n",
    "    create_node(label='Location', nodes=loc_name)\n",
    "\n",
    "    # 创建Node Person 存放一篇文章的所有人\n",
    "    person_name = 'Person'+title\n",
    "    create_node(label='Person', nodes=person_name)\n",
    "\n",
    "    # 创建Node Unit 存放一篇文章的所有组织ORG\n",
    "    org_name = 'ORG'+title\n",
    "    create_node(label='ORG', nodes=org_name)\n",
    "\n",
    "    # 创建relation Title has_content Content\n",
    "    create_relationship('Title', 'Content', title,\n",
    "                        content_name, 'Content', 'has_content')\n",
    "\n",
    "    # 创建relation Title has_file File\n",
    "    create_relationship('Title', 'File', title,\n",
    "                        text, 'File', 'has_file')\n",
    "\n",
    "    # 创建relation Title has_time Time\n",
    "    create_relationship('Title', 'Time', title,\n",
    "                        time_name, 'Time', 'has_time')\n",
    "\n",
    "    # 将所有子时间结点与Time（时间root）创建关系\n",
    "    for i in times:\n",
    "        create_node(label=i[1], nodes=i[0])\n",
    "        create_relationship('Time', i[1], time_name,\n",
    "                            i[0], 'time', 'has_Time')\n",
    "\n",
    "    # 创建relation Title has_person Person\n",
    "    create_relationship('Title', 'Person', title,\n",
    "                        person_name, 'Person', 'has_person')\n",
    "\n",
    "    # 将所有子结点与Person（root）创建关系\n",
    "    for i in person:\n",
    "        create_node(label=i[1], nodes=i[0])\n",
    "        create_relationship('Person', i[1], person_name,\n",
    "                            i[0], 'person', 'has_person')\n",
    "\n",
    "    create_relationship('Title', 'Location', title,\n",
    "                        loc_name, 'Location', 'has_location')\n",
    "\n",
    "    # 将所有子结点与Location（root）创建关系\n",
    "    for i in location:\n",
    "        create_node(label=i[1], nodes=i[0])\n",
    "        create_relationship('Location', i[1], loc_name,\n",
    "                            i[0], 'locatiion', 'has_location')\n",
    "\n",
    "    create_relationship('Title', 'ORG', title,\n",
    "                        org_name, 'ORG', 'has_org')\n",
    "\n",
    "    # 将所有子结点与ORG（root）创建关系\n",
    "    for i in unit:\n",
    "        create_node(label=i[1], nodes=i[0])\n",
    "        create_relationship('ORG', i[1], org_name,\n",
    "                            i[0], 'organization', 'has_organization')\n",
    "\n",
    "    # 为Content结点创建子节点\n",
    "    for i in relation:\n",
    "        start_node_name = i[0]\n",
    "        start_node_label = i[1]\n",
    "        rel_name = i[2]\n",
    "        rel_type = i[3]\n",
    "        end_node_name = i[4]\n",
    "        end_node_label = i[5]\n",
    "\n",
    "        create_node(label=i[5], nodes=i[4])\n",
    "        create_node(label=i[1], nodes=i[0])\n",
    "\n",
    "        create_relationship(start_node_label, end_node_label, start_node_name,\n",
    "                            end_node_name, rel_type, rel_name)\n",
    "\n",
    "        create_relationship('Content', end_node_label, content_name,\n",
    "                            end_node_name, 'Content', 'has_content')\n",
    "\n",
    "        create_relationship('Content', start_node_label, content_name,\n",
    "                            start_node_name, 'Content', 'has_content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b783f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集正式导入数据库\n",
    "from tqdm import tqdm\n",
    "\n",
    "# count = 0\n",
    "for i in tqdm(iterable=dataset, desc=\"loading\"):\n",
    "    try:\n",
    "        load_data(title=i[0], text=i[1])\n",
    "    except IndexError:\n",
    "        raise Exception(\"运行完成或IndexError\")\n",
    "\n",
    "    print(\"Success Loading!\")\n",
    "    # if count % 25 == 0:\n",
    "    #     f\"Success {count}/{len(dataset)}\"\n",
    "    # count += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
